{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "806ef61c-7192-411f-a1a5-737d6156423b",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97cace92-9360-451b-a92b-cb02d3b36844",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b6e9c68b-004c-484d-a906-68365232204c",
   "metadata": {},
   "source": [
    "## 서울교통공사_승하차_인원수year1231.csv \"총 승객수\" column만 남기기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "707672a4-ebcb-484e-88ce-42a0e744f451",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoding euc-kr failed for 서울교통공사_승하차_인원수20211231.csv. Trying next encoding...\n",
      "Error processing 서울교통공사_승하차_인원수20211231.csv: '승차총승객수'\n",
      "Encoding euc-kr failed for 서울교통공사_승하차_인원수20201231.csv. Trying next encoding...\n",
      "Error processing 서울교통공사_승하차_인원수20201231.csv: '승차총승객수'\n",
      "Encoding euc-kr failed for 서울교통공사_승하차_인원수20191231.csv. Trying next encoding...\n",
      "서울교통공사_승하차_인원수20191231.csv 파일을 성공적으로 처리하고 저장했습니다.\n",
      "Encoding euc-kr failed for 서울교통공사_승하차_인원수20181231.csv. Trying next encoding...\n",
      "서울교통공사_승하차_인원수20181231.csv 파일을 성공적으로 처리하고 저장했습니다.\n",
      "Encoding euc-kr failed for 서울교통공사_승하차_인원수20171231.csv. Trying next encoding...\n",
      "서울교통공사_승하차_인원수20171231.csv 파일을 성공적으로 처리하고 저장했습니다.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def read_csv_with_multiple_encodings(file_path, encodings=['euc-kr', 'utf-8', 'utf-8-sig']):\n",
    "    \"\"\"\n",
    "    여러 인코딩을 시도하여 CSV 파일을 읽습니다.\n",
    "    \"\"\"\n",
    "    for encoding in encodings:\n",
    "        try:\n",
    "            return pd.read_csv(file_path, encoding=encoding)\n",
    "        except UnicodeDecodeError:\n",
    "            print(f\"Encoding {encoding} failed for {file_path}. Trying next encoding...\")\n",
    "    raise ValueError(f\"Failed to read {file_path} with provided encodings.\")\n",
    "    \n",
    "file_paths = [\n",
    "    '서울교통공사_승하차_인원수20221231.csv',\n",
    "    '서울교통공사_승하차_인원수20211231.csv',\n",
    "    '서울교통공사_승하차_인원수20201231.csv',\n",
    "    '서울교통공사_승하차_인원수20191231.csv',\n",
    "    '서울교통공사_승하차_인원수20181231.csv',\n",
    "    '서울교통공사_승하차_인원수20171231.csv'\n",
    "]\n",
    "\n",
    "# 각 파일에 대해 반복 작업을 수행합니다.\n",
    "for file_path in file_paths:\n",
    "    try:\n",
    "        # 여러 인코딩을 시도하여 CSV 파일을 읽습니다.\n",
    "        passenger_df = read_csv_with_multiple_encodings(file_path)\n",
    "\n",
    "        # \"승차총승객수\"와 \"하차총승객수\"를 더하여 \"총 승객수\" 컬럼 생성\n",
    "        passenger_df['총 승객수'] = passenger_df['승차총승객수'] + passenger_df['하차총승객수']\n",
    "\n",
    "        # \"역명\"별로 \"총 승객수\" 집계\n",
    "        total_passengers_by_station = passenger_df.groupby('역명')['총 승객수'].sum().reset_index()\n",
    "\n",
    "        # 결과를 같은 파일 이름으로 저장\n",
    "        total_passengers_by_station.to_csv(file_path, index=False, encoding='utf-8-sig')\n",
    "\n",
    "        print(f\"{file_path} 파일을 성공적으로 처리하고 저장했습니다.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {file_path}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6ffabf8-3c16-49cd-9b6f-0e442a8b4a48",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e7d8e6bf-505b-4233-98e7-11197647ea45",
   "metadata": {},
   "source": [
    "## 서울교통공사_승하차_인원수year1231.csv 소괄호 제거"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "8ece5cab-abc5-435e-9329-99d05d2430cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoding euc-kr failed for 서울교통공사_승하차_인원수20211231.csv. Trying next encoding...\n",
      "서울교통공사_승하차_인원수20211231_cleaned_v2.csv 파일을 성공적으로 처리하고 저장했습니다.\n",
      "Encoding euc-kr failed for 서울교통공사_승하차_인원수20201231.csv. Trying next encoding...\n",
      "서울교통공사_승하차_인원수20201231_cleaned_v2.csv 파일을 성공적으로 처리하고 저장했습니다.\n",
      "Encoding euc-kr failed for 서울교통공사_승하차_인원수20191231.csv. Trying next encoding...\n",
      "서울교통공사_승하차_인원수20191231_cleaned_v2.csv 파일을 성공적으로 처리하고 저장했습니다.\n",
      "Encoding euc-kr failed for 서울교통공사_승하차_인원수20181231.csv. Trying next encoding...\n",
      "서울교통공사_승하차_인원수20181231_cleaned_v2.csv 파일을 성공적으로 처리하고 저장했습니다.\n",
      "Encoding euc-kr failed for 서울교통공사_승하차_인원수20171231.csv. Trying next encoding...\n",
      "서울교통공사_승하차_인원수20171231_cleaned_v2.csv 파일을 성공적으로 처리하고 저장했습니다.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def read_csv_with_multiple_encodings(file_path, encodings=['euc-kr', 'utf-8', 'utf-8-sig']):\n",
    "    \"\"\"\n",
    "    여러 인코딩을 시도하여 CSV 파일을 읽습니다.\n",
    "    \"\"\"\n",
    "    for encoding in encodings:\n",
    "        try:\n",
    "            return pd.read_csv(file_path, encoding=encoding)\n",
    "        except UnicodeDecodeError:\n",
    "            print(f\"Encoding {encoding} failed for {file_path}. Trying next encoding...\")\n",
    "    raise ValueError(f\"Failed to read {file_path} with provided encodings.\")\n",
    "\n",
    "# 파일 경로와 파일 이름을 리스트로 저장합니다.\n",
    "file_paths = [\n",
    "    '서울교통공사_승하차_인원수20221231.csv',\n",
    "    '서울교통공사_승하차_인원수20211231.csv',\n",
    "    '서울교통공사_승하차_인원수20201231.csv',\n",
    "    '서울교통공사_승하차_인원수20191231.csv',\n",
    "    '서울교통공사_승하차_인원수20181231.csv',\n",
    "    '서울교통공사_승하차_인원수20171231.csv'\n",
    "]\n",
    "\n",
    "# 각 파일에 대해 반복 작업을 수행합니다.\n",
    "for file_path in file_paths:\n",
    "    try:\n",
    "        # 여러 인코딩을 시도하여 CSV 파일을 읽습니다.\n",
    "        passenger_df = read_csv_with_multiple_encodings(file_path)\n",
    "\n",
    "        # \"역명\" 컬럼에서 괄호와 그 안의 내용을 제거\n",
    "        passenger_df['역명'] = passenger_df['역명'].str.replace(r'\\(.*\\)', '', regex=True)\n",
    "\n",
    "        # 결과를 새로운 CSV 파일로 저장\n",
    "        new_file_path = file_path.replace('.csv', '_cleaned_v2.csv')\n",
    "        passenger_df.to_csv(new_file_path, index=False, encoding='utf-8-sig')\n",
    "\n",
    "        print(f\"{new_file_path} 파일을 성공적으로 처리하고 저장했습니다.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {file_path}: {e}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17a925b7-1a94-453c-9aac-5f3622bbe52c",
   "metadata": {},
   "source": [
    "## 서울교통공사_지하역사_공기질_측정_정보.csv 소괄호 제거"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "31315d2c-997b-4b5b-b97e-34adddfbdf69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 연도 리스트 생성\n",
    "years = range(2017, 2023)\n",
    "\n",
    "# 반복 작업 수행\n",
    "for year in years:\n",
    "    try:\n",
    "        # 파일 읽기\n",
    "        file_name = f'서울교통공사_지하역사_공기질_측정_정보_{year}1231.csv'\n",
    "        df = pd.read_csv(f'{file_name}', encoding='euc-kr')\n",
    "        \n",
    "        # \"역명\" 컬럼에서 괄호와 그 안의 내용을 제거\n",
    "        df['역명'] = df['역명'].str.replace(r'\\(.*\\)', '', regex=True)\n",
    "        \n",
    "        # 결과를 새로운 CSV 파일로 저장\n",
    "        cleaned_file_name = f'서울교통공사_지하역사_공기질_측정_정보_{year}1231_cleaned_v2.csv'\n",
    "        df.to_csv(f'{cleaned_file_name}', index=False, encoding='utf-8-sig')\n",
    "    except FileNotFoundError:\n",
    "        print(f'{file_name} 파일을 찾을 수 없습니다.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef9351c4-8340-4743-8c70-505bb76641d3",
   "metadata": {},
   "source": [
    "## Column명 맞추기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "1c83ab8b-37af-4511-8ca4-9c700038b389",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Index(['역명', '미세먼지', '이산화탄소', '폼알데하이드', '일산화탄소'], dtype='object'),\n",
       " Index(['역명', '미세먼지', '이산화탄소', '폼알데하이드', '일산화탄소'], dtype='object'),\n",
       " Index(['역명', '미세먼지', '이산화탄소', '폼알데하이드', '일산화탄소'], dtype='object'),\n",
       " Index(['역명', '미세먼지', '이산화탄소', '폼알데하이드', '일산화탄소'], dtype='object'),\n",
       " Index(['역명', '미세먼지', '이산화탄소', '폼알데하이드', '일산화탄소'], dtype='object'),\n",
       " Index(['역명', '미세먼지', '이산화탄소', '폼알데하이드', '일산화탄소'], dtype='object'))"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_2017 = pd.read_csv('서울교통공사_지하역사_공기질_측정_정보_20171231_cleaned_v2.csv')\n",
    "df_2018 = pd.read_csv('서울교통공사_지하역사_공기질_측정_정보_20181231_cleaned_v2.csv')\n",
    "df_2019 = pd.read_csv('서울교통공사_지하역사_공기질_측정_정보_20191231_cleaned_v2.csv')\n",
    "df_2020 = pd.read_csv('서울교통공사_지하역사_공기질_측정_정보_20201231_cleaned_v2.csv')\n",
    "df_2021 = pd.read_csv('서울교통공사_지하역사_공기질_측정_정보_20211231_cleaned_v2.csv')\n",
    "df_2022 = pd.read_csv('서울교통공사_지하역사_공기질_측정_정보_20221231_cleaned_v2.csv')\n",
    "\n",
    "# 2017년 데이터 컬럼 이름 변경 및 필요 없는 컬럼 삭제\n",
    "df_2017 = df_2017.rename(columns={\n",
    "    '역명': '역명',\n",
    "    '유지기준 PM10 (㎍/㎥)140이하': '미세먼지',\n",
    "    '유지기준 CO2(ppm)1000이하': '이산화탄소',\n",
    "    '유지기준 Rn(Bq/㎥) 148 이하': '폼알데하이드',\n",
    "    '유지기준 CO(ppm)9이하': '일산화탄소'\n",
    "})\n",
    "\n",
    "# 2018년 데이터 컬럼 이름 변경\n",
    "df_2018 = df_2018.rename(columns={\n",
    "    '역명': '역명',\n",
    "    '미세먼지_PM-10(140 ㎍/㎥ 이하)': '미세먼지',\n",
    "    '이산화탄소_CO2 (1000 ppm 이하)': '이산화탄소',\n",
    "    '포름알데히드_HCHO(100 ㎍/㎥ 이하)': '폼알데하이드',\n",
    "    '일산화탄소_CO(9 ppm이하)': '일산화탄소'\n",
    "})\n",
    "\n",
    "# 2019년 데이터 컬럼 이름 변경\n",
    "df_2019 = df_2019.rename(columns={\n",
    "    '포름알데히드': '폼알데하이드'\n",
    "})\n",
    "\n",
    "# 2020년 데이터 컬럼 이름 변경\n",
    "df_2020 = df_2020.rename(columns={\n",
    "    '포름알데히드': '폼알데하이드'\n",
    "})\n",
    "\n",
    "# 2021년 데이터 컬럼 이름 변경\n",
    "df_2021 = df_2021.rename(columns={\n",
    "    '포름알데히드': '폼알데하이드'\n",
    "})\n",
    "\n",
    "# 데이터에서 필요 없는 컬럼 삭제\n",
    "df_2017 = df_2017[['역명', '미세먼지', '이산화탄소', '폼알데하이드', '일산화탄소']]\n",
    "df_2018 = df_2018[['역명', '미세먼지', '이산화탄소', '폼알데하이드', '일산화탄소']]\n",
    "df_2019 = df_2019[['역명', '미세먼지', '이산화탄소', '폼알데하이드', '일산화탄소']]\n",
    "df_2020 = df_2020[['역명', '미세먼지', '이산화탄소', '폼알데하이드', '일산화탄소']]\n",
    "df_2021 = df_2021[['역명', '미세먼지', '이산화탄소', '폼알데하이드', '일산화탄소']]\n",
    "df_2022 = df_2022[['역명', '미세먼지', '이산화탄소', '폼알데하이드', '일산화탄소']]\n",
    "\n",
    "# 컬럼 이름 일치 확인\n",
    "df_2017.columns, df_2018.columns, df_2019.columns, df_2020.columns, df_2021.columns, df_2022.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "84d92730-b17d-4fa8-836c-adb918ec8693",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2017.to_csv('서울교통공사_지하역사_공기질_측정_정보_20171231_cleaned_v2.csv', index=False, encoding='utf-8-sig')\n",
    "df_2018.to_csv('서울교통공사_지하역사_공기질_측정_정보_20181231_cleaned_v2.csv', index=False, encoding='utf-8-sig')\n",
    "df_2019.to_csv('서울교통공사_지하역사_공기질_측정_정보_20191231_cleaned_v2.csv', index=False, encoding='utf-8-sig')\n",
    "df_2020.to_csv('서울교통공사_지하역사_공기질_측정_정보_20201231_cleaned_v2.csv', index=False, encoding='utf-8-sig')\n",
    "df_2021.to_csv('서울교통공사_지하역사_공기질_측정_정보_20211231_cleaned_v2.csv', index=False, encoding='utf-8-sig')\n",
    "df_2022.to_csv('서울교통공사_지하역사_공기질_측정_정보_20221231_cleaned_v2.csv', index=False, encoding='utf-8-sig')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e935634f-1c9f-42ec-aceb-2065985c78b5",
   "metadata": {},
   "source": [
    "## 공기질 파일, 승하차 파일: '서울역' -> '서울' 변경"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "0851b7cf-e600-4495-bb18-69bae3c637cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "서울교통공사_승하차_인원수20221231_cleaned_v2.csv 파일의 '역명' 컬럼에서 '서울역' 값을 '서울'로 변경하여 저장했습니다.\n",
      "서울교통공사_승하차_인원수20211231_cleaned_v2.csv 파일의 '역명' 컬럼에서 '서울역' 값을 '서울'로 변경하여 저장했습니다.\n",
      "서울교통공사_승하차_인원수20201231_cleaned_v2.csv 파일의 '역명' 컬럼에서 '서울역' 값을 '서울'로 변경하여 저장했습니다.\n",
      "서울교통공사_승하차_인원수20191231_cleaned_v2.csv 파일의 '역명' 컬럼에서 '서울역' 값을 '서울'로 변경하여 저장했습니다.\n",
      "서울교통공사_승하차_인원수20181231_cleaned_v2.csv 파일의 '역명' 컬럼에서 '서울역' 값을 '서울'로 변경하여 저장했습니다.\n",
      "서울교통공사_승하차_인원수20171231_cleaned_v2.csv 파일의 '역명' 컬럼에서 '서울역' 값을 '서울'로 변경하여 저장했습니다.\n"
     ]
    }
   ],
   "source": [
    "## 승하차 ##\n",
    "\n",
    "# 파일 경로 리스트\n",
    "file_paths = [\n",
    "    '서울교통공사_승하차_인원수20221231_cleaned_v2.csv',\n",
    "    '서울교통공사_승하차_인원수20211231_cleaned_v2.csv',\n",
    "    '서울교통공사_승하차_인원수20201231_cleaned_v2.csv',\n",
    "    '서울교통공사_승하차_인원수20191231_cleaned_v2.csv',\n",
    "    '서울교통공사_승하차_인원수20181231_cleaned_v2.csv',\n",
    "    '서울교통공사_승하차_인원수20171231_cleaned_v2.csv'\n",
    "]\n",
    "\n",
    "# 각 파일에 대해 반복 작업을 수행합니다.\n",
    "for file_path in file_paths:\n",
    "    # CSV 파일을 읽습니다.\n",
    "    passenger_df = pd.read_csv(file_path, encoding='utf-8-sig')\n",
    "\n",
    "    # '역명' 컬럼에서 '서울역' 값을 '서울'로 변경\n",
    "    passenger_df['역명'] = passenger_df['역명'].str.replace('서울역', '서울')\n",
    "\n",
    "    # 수정된 데이터를 다시 저장\n",
    "    passenger_df.to_csv(file_path, index=False, encoding='utf-8-sig')\n",
    "    \n",
    "    print(f\"{file_path} 파일의 '역명' 컬럼에서 '서울역' 값을 '서울'로 변경하여 저장했습니다.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "42c10dd0-e397-487b-b20f-7e5bbbcd3fa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 공기질 ##\n",
    "\n",
    "# CSV 파일 읽기\n",
    "air_quality_df = pd.read_csv('서울교통공사_지하역사_공기질_측정_정보_20221231_cleaned_v2.csv')\n",
    "\n",
    "# '역명' 컬럼에서 '서울역' 값을 '서울'로 변경\n",
    "air_quality_df['역명'] = air_quality_df['역명'].str.replace('서울역', '서울')\n",
    "\n",
    "# 수정된 데이터를 다시 저장\n",
    "air_quality_df.to_csv('서울교통공사_지하역사_공기질_측정_정보_20221231_cleaned_v2.csv', index=False, encoding='utf-8-sig')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "dd35646f-b486-443c-992b-f45f1402f0d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "모든 파일이 개별적으로 수정 및 저장되었습니다.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 파일 경로 리스트\n",
    "file_paths = [\n",
    "    '서울교통공사_지하역사_공기질_측정_정보_20171231_cleaned_v2.csv',\n",
    "    '서울교통공사_지하역사_공기질_측정_정보_20181231_cleaned_v2.csv',\n",
    "    '서울교통공사_지하역사_공기질_측정_정보_20191231_cleaned_v2.csv',\n",
    "    '서울교통공사_지하역사_공기질_측정_정보_20201231_cleaned_v2.csv',\n",
    "    '서울교통공사_지하역사_공기질_측정_정보_20211231_cleaned_v2.csv',\n",
    "    '서울교통공사_지하역사_공기질_측정_정보_20221231_cleaned_v2.csv'\n",
    "]\n",
    "\n",
    "# 각 파일을 처리하여 '역명' 컬럼의 값을 수정하고 저장\n",
    "for file_path in file_paths:\n",
    "    # CSV 파일 읽기\n",
    "    df = pd.read_csv(file_path)\n",
    "    \n",
    "    # '서울역' 값을 '서울'로 변경\n",
    "    df['역명'] = df['역명'].str.replace('서울역', '서울')\n",
    "    \n",
    "    # '역명' 컬럼에서 숫자 제거\n",
    "    df['역명'] = df['역명'].str.replace(r'\\d+', '', regex=True)\n",
    "    \n",
    "    # 변경된 데이터를 다시 저장\n",
    "    df.to_csv(file_path, index=False, encoding='utf-8-sig')\n",
    "\n",
    "# 개별 저장 완료 후 확인\n",
    "print(\"모든 파일이 개별적으로 수정 및 저장되었습니다.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d0d8bce4-494d-4e28-ae64-909e7a91b9fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CSV 파일을 읽어 데이터프레임으로 변환\n",
    "coordinate_df = pd.read_csv('서울교통공사_1_8호선_역사_좌표(위경도)정보_20231031.csv', encoding='euc-kr')\n",
    "air_quality_df = pd.read_csv('서울교통공사_지하역사_공기질_측정_정보_20221231_cleaned_v2.csv')\n",
    "passenger_df = pd.read_csv('서울교통공사_승하차_인원수20221231_cleaned_v2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b8db69c4-4140-4435-8f8b-d897205c0f07",
   "metadata": {},
   "outputs": [],
   "source": [
    "air_quality_df_21 = pd.read_csv('서울교통공사_지하역사_공기질_측정_정보_20211231_cleaned_v2.csv')\n",
    "air_quality_df_20 = pd.read_csv('서울교통공사_지하역사_공기질_측정_정보_20201231_cleaned_v2.csv')\n",
    "air_quality_df_19 = pd.read_csv('서울교통공사_지하역사_공기질_측정_정보_20191231_cleaned_v2.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6afc8701-5b08-44e5-b4eb-4241f8c03345",
   "metadata": {},
   "source": [
    "## 역사_좌표(위경도) / 공기질 측정 정보 / 승하차 인원수 사이의 공통된 역명 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8a435dee-24fd-48c1-8550-6e9c9bc37425",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "세 파일 모두에 공통된 역명 값: {'산성', '애오개', '미사', '수서', '신길', '아현', '신정네거리', '청담', '이대', '숙대입구', '성신여대입구', '모란', '잠실새내', '상봉', '강남', '마포', '대흥', '미아사거리', '석촌', '수유', '가락시장', '군자', '단대오거리', '신설동', '독바위', '중계', '철산', '남한산성입구', '낙성대', '문래', '보문', '창신', '수락산', '용마산', '연신내', '건대입구', '일원', '학여울', '여의나루', '홍제', '충정로', '충무로', '고속터미널', '오금', '우장산', '을지로입구', '종로3가', '종합운동장', '둔촌동', '신림', '월곡', '디지털미디어시티', '길동', '강동구청', '신사', '길음', '숭실대입구', '대치', '돌곶이', '강남구청', '망원', '신흥', '개화산', '신도림', '광나루', '버티고개', '방배', '장승배기', '구파발', '강동', '홍대입구', '신당', '암사', '선릉', '용두', '동대입구', '이촌', '양재', '삼성', '월드컵경기장', '공릉', '신정', '양천구청', '장한평', '봉천', '마들', '왕십리', '고덕', '대청', '사당', '광화문', '반포', '공덕', '교대', '남구로', '불광', '마곡', '삼각지', '증산', '도곡', '동대문역사문화공원', '총신대입구', '독립문', '회현', '상수', '명동', '서초', '동대문', '청량리', '송정', '수진', '하계', '대림', '천왕', '제기동', '명일', '상왕십리', '마장', '오목교', '어린이대공원', '개롱', '여의도', '신촌', '양평', '화곡', '종각', '한성대입구', '쌍문', '문정', '서울', '상일동', '합정', '혜화', '마천', '역촌', '석계', '내방', '응암', '녹사평', '상월곡', '을지로4가', '올림픽공원', '가산디지털단지', '김포공항', '무악재', '고려대', '남성', '역삼', '영등포시장', '경복궁', '광명사거리', '신금호', '거여', '답십리', '미아', '학동', '봉화산', '종로5가', '먹골', '노원', '매봉', '장지', '이태원', '몽촌토성', '복정', '압구정', '영등포구청', '약수', '시청', '동묘앞', '신대방삼거리', '중화', '신풍', '경찰병원', '사가정', '방이', '청구', '한강진', '새절', '안암', '굽은다리', '논현', '온수', '강일', '남태령', '방화', '녹번', '아차산', '행당', '하남검단산', '발산', '광흥창', '태릉입구', '까치산', '송파', '상도', '서울대입구', '면목', '목동', '남부터미널', '구산', '신용산', '을지로3가', '중곡', '하남시청', '서대문', '금호', '보라매', '도림천', '안국', '하남풍산', '잠실', '천호', '효창공원앞', '화랑대', '잠원', '마포구청'}\n",
      "\n",
      "공기질 측정 파일에만 있는 역명 값: set()\n",
      "\n",
      "승하차 인원수 파일에만 있는 역명 값: set()\n",
      "\n",
      "좌표 파일에만 있는 역명 값: {'성수', '구의', '잠실나루', '한양대', '당고개', '동작', '도봉산', '창동', '옥수', '장암', '지축', '신대방', '남위례', '신답', '구로디지털단지', '상계', '뚝섬유원지', '당산', '신내', '뚝섬', '강변', '용답'}\n"
     ]
    }
   ],
   "source": [
    "# 각 데이터프레임에서 \"역명\" 값 추출\n",
    "coordinate_stations = set(coordinate_df['역명'])\n",
    "air_quality_stations = set(air_quality_df['역명'])\n",
    "passenger_stations = set(passenger_df['역명'])\n",
    "\n",
    "# 공통된 역명 확인\n",
    "common_stations_all = coordinate_stations & air_quality_stations & passenger_stations\n",
    "\n",
    "# 좌표 파일과 공기질 측정 파일 간의 공통된 역명 확인\n",
    "common_stations_coordinate_air_quality = coordinate_stations & air_quality_stations\n",
    "# 좌표 파일과 승하차 인원수 파일 간의 공통된 역명 확인\n",
    "common_stations_coordinate_passenger = coordinate_stations & passenger_stations\n",
    "# 공기질 측정 파일과 승하차 인원수 파일 간의 공통된 역명 확인\n",
    "common_stations_air_quality_passenger = air_quality_stations & passenger_stations\n",
    "\n",
    "# 공기질 측정 파일에만 있는 역명 값 확인\n",
    "air_quality_only_stations = air_quality_stations - (coordinate_stations | passenger_stations)\n",
    "# 승하차 인원수 파일에만 있는 역명 값 확인\n",
    "passenger_only_stations = passenger_stations - (coordinate_stations | air_quality_stations)\n",
    "# 좌표 파일에만 있는 역명 값 확인\n",
    "coordinate_only_stations = coordinate_stations - (air_quality_stations | passenger_stations)\n",
    "\n",
    "# 결과 출력\n",
    "print(\"세 파일 모두에 공통된 역명 값:\", common_stations_all)\n",
    "print()\n",
    "print(\"공기질 측정 파일에만 있는 역명 값:\", air_quality_only_stations)\n",
    "print()\n",
    "print(\"승하차 인원수 파일에만 있는 역명 값:\", passenger_only_stations)\n",
    "print()\n",
    "print(\"좌표 파일에만 있는 역명 값:\", coordinate_only_stations)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e2f32a6-cb4a-4f51-92af-7e2017be84b4",
   "metadata": {},
   "source": [
    "## 중복된 역명으로 파일 업데이트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ae5b901c-75d1-4721-b634-b921bca9c0e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "### 공기질 ###\n",
    "\n",
    "\n",
    "# 연도 리스트 생성\n",
    "years = range(2017, 2023)\n",
    "\n",
    "# 반복 작업 수행\n",
    "for year in years:\n",
    "    try:\n",
    "        # 파일 읽기\n",
    "        file_name = f'서울교통공사_지하역사_공기질_측정_정보_{year}1231_cleaned_v2.csv'\n",
    "        df = pd.read_csv(f'{file_name}')\n",
    "        \n",
    "        # 'common_stations_all'에 존재하는 '역명'만 남기기\n",
    "        df_filtered = df[df['역명'].isin(common_stations_all)]\n",
    "        \n",
    "        # 결과를 새로운 CSV 파일로 저장\n",
    "        cleaned_file_name = f'서울교통공사_지하역사_공기질_측정_정보_{year}1231_cleaned_v2.csv'\n",
    "        df_filtered.to_csv(cleaned_file_name, index=False, encoding='utf-8-sig')\n",
    "    except FileNotFoundError:\n",
    "        print(f'{file_name} 파일을 찾을 수 없습니다.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "5138ec0f-e73e-460e-9330-dce82d4981d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "서울교통공사_승하차_인원수20221231_cleaned_v2.csv 파일을 성공적으로 처리하고 저장했습니다.\n",
      "서울교통공사_승하차_인원수20211231_cleaned_v2.csv 파일을 성공적으로 처리하고 저장했습니다.\n",
      "서울교통공사_승하차_인원수20201231_cleaned_v2.csv 파일을 성공적으로 처리하고 저장했습니다.\n",
      "서울교통공사_승하차_인원수20191231_cleaned_v2.csv 파일을 성공적으로 처리하고 저장했습니다.\n",
      "서울교통공사_승하차_인원수20181231_cleaned_v2.csv 파일을 성공적으로 처리하고 저장했습니다.\n",
      "서울교통공사_승하차_인원수20171231_cleaned_v2.csv 파일을 성공적으로 처리하고 저장했습니다.\n"
     ]
    }
   ],
   "source": [
    "### 승하차 ###\n",
    "\n",
    "# 파일 경로 리스트\n",
    "file_paths = [\n",
    "    '서울교통공사_승하차_인원수20221231_cleaned_v2.csv',\n",
    "    '서울교통공사_승하차_인원수20211231_cleaned_v2.csv',\n",
    "    '서울교통공사_승하차_인원수20201231_cleaned_v2.csv',\n",
    "    '서울교통공사_승하차_인원수20191231_cleaned_v2.csv',\n",
    "    '서울교통공사_승하차_인원수20181231_cleaned_v2.csv',\n",
    "    '서울교통공사_승하차_인원수20171231_cleaned_v2.csv'\n",
    "]\n",
    "\n",
    "# 각 파일에 대해 반복 작업을 수행합니다.\n",
    "for file_path in file_paths:\n",
    "    try:\n",
    "        # 파일 읽기\n",
    "        df = pd.read_csv(file_path, encoding='utf-8-sig')\n",
    "        \n",
    "        # 'common_stations_all'에 존재하는 '역명'만 남기기\n",
    "        df_filtered = df[df['역명'].isin(common_stations_all)]\n",
    "        \n",
    "        # 결과를 같은 파일 이름으로 저장\n",
    "        df_filtered.to_csv(file_path, index=False, encoding='utf-8-sig')\n",
    "        \n",
    "        print(f\"{file_path} 파일을 성공적으로 처리하고 저장했습니다.\")\n",
    "    except FileNotFoundError:\n",
    "        print(f'{file_path} 파일을 찾을 수 없습니다.')\n",
    "    except Exception as e:\n",
    "        print(f'{file_path} 파일 처리 중 오류 발생: {e}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c87d2fd2-99e7-4313-a389-c8e4de415f07",
   "metadata": {},
   "source": [
    "## 업데이트 되었는지 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "b5b6666b-3fee-45c9-b658-87bce742db8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CSV 파일을 읽어 데이터프레임으로 변환\n",
    "coordinate_df = pd.read_csv('서울교통공사_1_8호선_역사_좌표(위경도)정보_20231031.csv', encoding='euc-kr')\n",
    "air_quality_df = pd.read_csv('서울교통공사_지하역사_공기질_측정_정보_20221231_cleaned_v2.csv')\n",
    "passenger_df = pd.read_csv('서울교통공사_승하차_인원수20221231_cleaned_v2.csv')\n",
    "\n",
    "# 각 데이터프레임에서 \"역명\" 값 추출\n",
    "coordinate_stations = set(coordinate_df['역명'])\n",
    "air_quality_stations = set(air_quality_df['역명'])\n",
    "passenger_stations = set(passenger_df['역명'])\n",
    "\n",
    "# 공기질 측정 파일에만 있는 역명 값 확인\n",
    "air_quality_only_stations = air_quality_stations - (coordinate_stations | passenger_stations)\n",
    "# 승하차 인원수 파일에만 있는 역명 값 확인\n",
    "passenger_only_stations = passenger_stations - (coordinate_stations | air_quality_stations)\n",
    "# 좌표 파일에만 있는 역명 값 확인\n",
    "coordinate_only_stations = coordinate_stations - (air_quality_stations | passenger_stations)\n",
    "\n",
    "# 공통된 역명 확인\n",
    "common_stations_all = coordinate_stations & air_quality_stations & passenger_stations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "45dc11f8-3b7f-4988-8d77-7f7a04a3f67b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "세 파일 모두에 공통된 역명 값: {'산성', '애오개', '미사', '수서', '신길', '아현', '신정네거리', '청담', '이대', '숙대입구', '성신여대입구', '모란', '잠실새내', '강남', '상봉', '마포', '대흥', '미아사거리', '신설동', '수유', '가락시장', '군자', '중계', '석촌', '독바위', '단대오거리', '철산', '남한산성입구', '낙성대', '문래', '보문', '창신', '수락산', '용마산', '연신내', '홍제', '학여울', '일원', '여의나루', '건대입구', '충정로', '충무로', '을지로입구', '종합운동장', '고속터미널', '오금', '우장산', '신림', '둔촌동', '월곡', '디지털미디어시티', '길동', '강동구청', '신사', '길음', '숭실대입구', '대치', '돌곶이', '망원', '강남구청', '신흥', '개화산', '신도림', '광나루', '버티고개', '방배', '장승배기', '구파발', '강동', '홍대입구', '신당', '암사', '선릉', '용두', '동대입구', '이촌', '양재', '삼성', '월드컵경기장', '공릉', '신정', '양천구청', '장한평', '봉천', '마들', '왕십리', '고덕', '대청', '사당', '광화문', '반포', '교대', '불광', '공덕', '남구로', '마곡', '삼각지', '증산', '도곡', '동대문역사문화공원', '총신대입구', '독립문', '회현', '상수', '명동', '서초', '동대문', '청량리', '송정', '수진', '하계', '대림', '천왕', '제기동', '명일', '상왕십리', '마장', '오목교', '어린이대공원', '여의도', '개롱', '신촌', '화곡', '양평', '종각', '한성대입구', '쌍문', '문정', '서울', '상일동', '합정', '혜화', '마천', '역촌', '응암', '석계', '내방', '녹사평', '상월곡', '올림픽공원', '무악재', '김포공항', '가산디지털단지', '고려대', '영등포시장', '역삼', '남성', '경복궁', '광명사거리', '신금호', '미아', '답십리', '거여', '학동', '봉화산', '먹골', '노원', '매봉', '장지', '이태원', '압구정', '몽촌토성', '복정', '영등포구청', '약수', '시청', '동묘앞', '신대방삼거리', '중화', '신풍', '경찰병원', '청구', '방이', '한강진', '사가정', '새절', '안암', '굽은다리', '논현', '온수', '남태령', '방화', '강일', '녹번', '행당', '아차산', '하남검단산', '발산', '광흥창', '태릉입구', '까치산', '송파', '서울대입구', '상도', '면목', '목동', '남부터미널', '신용산', '구산', '하남시청', '중곡', '서대문', '금호', '보라매', '도림천', '안국', '하남풍산', '잠실', '천호', '효창공원앞', '화랑대', '잠원', '마포구청'}\n",
      "\n",
      "공기질 측정 파일에만 있는 역명 값: {'둔촌오륜', '선정릉', '봉은사', '언주', '을지로가', '석촌고분', '삼성중앙', '한성백제', '종로가', '이수', '삼전', '송파나루', '중앙보훈병원'}\n",
      "\n",
      "승하차 인원수 파일에만 있는 역명 값: set()\n",
      "\n",
      "좌표 파일에만 있는 역명 값: {'성수', '구의', '잠실나루', '한양대', '당고개', '동작', '도봉산', '창동', '옥수', '장암', '지축', '신대방', '남위례', '신답', '구로디지털단지', '상계', '뚝섬유원지', '당산', '신내', '뚝섬', '강변', '용답'}\n"
     ]
    }
   ],
   "source": [
    "# 결과 출력\n",
    "print(\"세 파일 모두에 공통된 역명 값:\", common_stations_all)\n",
    "print()\n",
    "print(\"공기질 측정 파일에만 있는 역명 값:\", air_quality_only_stations)\n",
    "print()\n",
    "print(\"승하차 인원수 파일에만 있는 역명 값:\", passenger_only_stations)\n",
    "print()\n",
    "print(\"좌표 파일에만 있는 역명 값:\", coordinate_only_stations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e328073c-4014-495c-bffd-1e837814ffb8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "196038fe-8da1-4d64-bea3-e105cc1420ef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d9e23f21-0a10-4b98-867c-9522e0a49e09",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "249"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1 = pd.read_csv('위도경도기준_공기질_승차인원수.csv') #, encoding='euc-kr')\n",
    "len(df1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "63580533-8a76-4a3b-be1b-5c4f958f0962",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "276"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2 = pd.read_csv('서울교통공사_1_8호선_역사_좌표(위경도)정보_20231031.csv', encoding='euc-kr')\n",
    "len(df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f60a450-1e88-40f7-9328-56107560f85b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "132da19b-df2b-4571-9553-e211c5c8e83b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
